{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ddea3a4",
   "metadata": {},
   "source": [
    "feature selection techniques\n",
    "\n",
    "including ANOVA, Chi-Squared, Forward Selection, Recursive Feature Elimination (RFE), Random Forestbased selection, and Decision TREE "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9688c2",
   "metadata": {},
   "source": [
    "# import and setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad8bba2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0503aa31",
   "metadata": {},
   "source": [
    " input variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3eb95368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base path\n",
    "base_path1 = \"/Users/priyam/paper_recreation/UCI_HAR_FEATURE_ANALYSIS_MODELLING/stage1_Custom Feature_Extraction_ModelTraining/DATA_EXTRACTED_WITH_99_FEATURES\"\n",
    "\n",
    "# Load clean data\n",
    "X = pd.read_csv(os.path.join(base_path1, \"X_CLEAN.csv\"))\n",
    "y = pd.read_csv(os.path.join(base_path1, \"Y_CLEAN.csv\")).values.ravel()\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a21e6b",
   "metadata": {},
   "source": [
    " defining the models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e47749d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c568c096",
   "metadata": {},
   "source": [
    "# model evaluation and training "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f574d7",
   "metadata": {},
   "source": [
    "#### FETAURE SELCTION method list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea73e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === FEATURE SELECTION METHODS ===\n",
    "feature_methods = {\n",
    "    \"ANOVA\": SelectKBest(score_func=f_classif, k=40),\n",
    "    \"ChiSquared\": SelectKBest(score_func=chi2, k=40),\n",
    "    \"RFE\": RFE(estimator=LogisticRegression(max_iter=1000), n_features_to_select=40),\n",
    "    \"ForwardSelection\": SequentialFeatureSelector(estimator=LogisticRegression(max_iter=500), n_features_to_select=40, direction='forward'),\n",
    "    \"RandomForestImportance\": RandomForestClassifier(),\n",
    "    \"DecisionTreeImportance\": DecisionTreeClassifier()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c21f199",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ca90fb9",
   "metadata": {},
   "source": [
    " MODEL EVALUATION funcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "228cade5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === EVALUATION FUNCTION ===\n",
    "def evaluate_model(y_test, y_pred):\n",
    "    return {\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"F1\": f1_score(y_test, y_pred, average='weighted'),\n",
    "        \"Precision\": precision_score(y_test, y_pred, average='weighted'),\n",
    "        \"Recall\": recall_score(y_test, y_pred, average='weighted')\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fab388",
   "metadata": {},
   "source": [
    "#### main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c456ccf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = X.columns.tolist() if isinstance(X, pd.DataFrame) else [f\"Feature {i}\" for i in range(X.shape[1])]\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "baf28756",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path= \"/Users/priyam/paper_recreation/UCI_HAR_FEATURE_ANALYSIS_MODELLING/stage3_FeatureSelection_ModelEvaluation/CUSTOM_DATASET/COMPARISON_TABLES_40_FEATURES\"\n",
    "if not os.path.exists(base_path):\n",
    "    os.makedirs(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b692c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main loop\n",
    "feature_names = X.columns.tolist() if isinstance(X, pd.DataFrame) else [f\"Feature {i}\" for i in range(X.shape[1])]\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "\n",
    "for method_name, selector in feature_methods.items():\n",
    "    print(f\"\\nüîç Feature Selection: {method_name}\")\n",
    "\n",
    "    # Normalize for Chi-Squared\n",
    "    if method_name == \"ChiSquared\":\n",
    "        X_scaled = MinMaxScaler().fit_transform(X)\n",
    "    else:\n",
    "        X_scaled = X.copy()\n",
    "\n",
    "    # Feature selection\n",
    "    if method_name in [\"RandomForestImportance\", \"DecisionTreeImportance\"]:\n",
    "        selector.fit(X_scaled, y)\n",
    "        importances = selector.feature_importances_\n",
    "        top_k_indices = np.argsort(importances)[-40:]\n",
    "        selected_features = top_k_indices.tolist()\n",
    "        # Convert to NumPy if DataFrame\n",
    "        if isinstance(X_scaled, pd.DataFrame):\n",
    "            X_selected = X_scaled.iloc[:, top_k_indices].values\n",
    "        else:\n",
    "            X_selected = X_scaled[:, top_k_indices]\n",
    "\n",
    "        # Plot\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        plt.barh(range(22), importances[top_k_indices])\n",
    "        plt.yticks(ticks=range(22), labels=np.array(feature_names)[top_k_indices])\n",
    "        plt.xlabel(\"Importance\")\n",
    "        plt.title(f\"{method_name} - Top 40 Features\")\n",
    "        plot_path = os.path.join(base_path, f\"{method_name}_RESULTS\", f\"{method_name}_feature_importance.png\")\n",
    "        os.makedirs(os.path.dirname(plot_path), exist_ok=True)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(plot_path)\n",
    "        plt.close()\n",
    "    \n",
    "    else:\n",
    "        selector.fit(X_scaled, y)\n",
    "        mask = selector.get_support()\n",
    "        selected_features = np.where(mask)[0].tolist()\n",
    "        # Convert to NumPy if DataFrame\n",
    "        if isinstance(X_scaled, pd.DataFrame):\n",
    "            X_selected = X_scaled.iloc[:, mask].values\n",
    "        else:\n",
    "            X_selected = X_scaled[:, mask]\n",
    "            \n",
    "        \n",
    "    # Save selected features\n",
    "    selected_feature_names = [feature_names[i] for i in selected_features]\n",
    "    output_folder = os.path.join(base_path, f\"{method_name}_RESULTS\")\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    with open(os.path.join(output_folder, f\"{method_name}_selected_features.txt\"), 'w') as f:\n",
    "        for name in selected_feature_names:\n",
    "            f.write(name + '\\n')\n",
    "\n",
    "    # train and evaluate models with selected features\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    results = []\n",
    "    for model_name, model in models.items():\n",
    "        try:\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            scores = evaluate_model(y_test, y_pred)\n",
    "            results.append([model_name, scores[\"Accuracy\"], scores[\"F1\"], scores[\"Precision\"], scores[\"Recall\"]])\n",
    "        except Exception as e:\n",
    "            print(f\" Error in {model_name}: {e}\")\n",
    "            results.append([model_name, \"ERR\", \"ERR\", \"ERR\", \"ERR\"])\n",
    "    # Save results\n",
    "    output_folder = os.path.join(base_path, f\"{method_name}_RESULTS\")\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    df_results = pd.DataFrame(results, columns=[\"Model\", \"Accuracy\", \"F1 Score\", \"Precision\", \"Recall\"])\n",
    "    output_txt_path = os.path.join(output_folder, f\"{method_name}_model_scores.txt\")\n",
    "    \n",
    "    table_string = tabulate(df_results, headers='keys', tablefmt='grid', showindex=False)\n",
    "    \n",
    "    with open(output_txt_path, 'w') as f:\n",
    "        f.write(table_string)\n",
    "    \n",
    "    print(f\"‚úî Results saved to: {output_txt_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019bad54",
   "metadata": {},
   "source": [
    "# TOP 20 FEATURE PLOTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17eb475d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path2= \"/Users/priyam/paper_recreation/UCI_HAR_FEATURE_ANALYSIS_MODELLING/stage3_FeatureSelection_ModelEvaluation/CUSTOM_DATASET/TOP_20_FEATURE_PLOT\"\n",
    "os.makedirs(base_path2, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4417e523",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af28635e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y = np.array(y_test).ravel()     # Ensure y is a 1D array\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X_test)\n",
    "feature_names = X.columns if isinstance(X, pd.DataFrame) else [f\"f{i}\" for i in range(X.shape[1])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44ca0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}\n",
    "\n",
    "# ANOVA F-score\n",
    "anova_selector = feature_methods[\"ANOVA\"].fit(X_scaled, y)\n",
    "scores[\"F-score (ANOVA)\"] = anova_selector.scores_\n",
    "\n",
    "# Chi2\n",
    "chi2_selector = feature_methods[\"ChiSquared\"].fit(X_scaled, y)\n",
    "scores[\"Chi2 score\"] = chi2_selector.scores_\n",
    "\n",
    "# RFE\n",
    "rfe_selector = feature_methods[\"RFE\"].fit(X_scaled, y)\n",
    "scores[\"RFE ranking\"] = -rfe_selector.ranking_  # lower is better ‚Üí invert for plotting\n",
    "\n",
    "# Forward Selection\n",
    "fs_selector = feature_methods[\"ForwardSelection\"].fit(X_scaled, y)\n",
    "scores[\"Forward selection\"] = fs_selector.get_support().astype(int)  # 1 if selected\n",
    "\n",
    "# Random Forest Importance\n",
    "rf_model = feature_methods[\"RandomForestImportance\"].fit(X_scaled, y)\n",
    "scores[\"RandomForest Importance\"] = rf_model.feature_importances_\n",
    "\n",
    "# Decision Tree Importance\n",
    "dt_model = feature_methods[\"DecisionTreeImportance\"].fit(X_scaled, y)\n",
    "scores[\"DecisionTree Importance\"] = dt_model.feature_importances_\n",
    "\n",
    "\n",
    "score_df = pd.DataFrame(scores, index=feature_names)\n",
    "\n",
    "for score_type in score_df.columns:\n",
    "    top_20 = score_df[score_type].nlargest(20)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    top_20.plot(kind='barh')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.title(f\"Top 20 Features by {score_type}\")\n",
    "    plt.xlabel(\"Score\")\n",
    "    plt.tight_layout()\n",
    "    #plt.show()\n",
    "    \n",
    "    plot_path = os.path.join(base_path2, f\"{score_type}_top_20_features.png\")\n",
    "    plt.savefig(plot_path)\n",
    "    plt.close()\n",
    "    print(f\"‚úî Plot saved to: {plot_path}\")\n",
    "    # Save the DataFrame to a CSV file\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c120bac",
   "metadata": {},
   "source": [
    "# deciding k for each techniques \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b42c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path4= \"/Users/priyam/paper_recreation/HAR MODEL_OPTIMIZATION/stage3_FeatureSelection_ModelEvaluation/CUSTOM_DATASET/OUTPUT_CD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59cc67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === FEATURE SELECTION METHODS ===\n",
    "feature_methods = {\n",
    "    \"ANOVA\": SelectKBest(score_func=f_classif, k=20),\n",
    "    \"ChiSquared\": SelectKBest(score_func=chi2, k=28),\n",
    "    \"RFE\": RFE(estimator=LogisticRegression(max_iter=5000), n_features_to_select=10),\n",
    "    \"ForwardSelection\": SequentialFeatureSelector(estimator=LogisticRegression(max_iter=5000), n_features_to_select=10, direction='forward'),\n",
    "    \"RandomForestImportance\": RandomForestClassifier(),\n",
    "    \"DecisionTreeImportance\": DecisionTreeClassifier()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a3e360",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699f9b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import f_classif, chi2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for method_name, selector in feature_methods.items():\n",
    "    print(f\"üìä Feature Score Visualization: {method_name}\")\n",
    "    \n",
    "    if method_name == \"ChiSquared\":\n",
    "        X_scaled = MinMaxScaler().fit_transform(X)\n",
    "    else:\n",
    "        X_scaled = X.copy()\n",
    "        \n",
    "    if method_name in [\"RandomForestImportance\", \"DecisionTreeImportance\"]:\n",
    "        selector.fit(X_scaled, y)\n",
    "        scores = selector.feature_importances_\n",
    "\n",
    "    elif method_name == \"ANOVA\":\n",
    "        scores, _ = f_classif(X_scaled, y)\n",
    "\n",
    "    elif method_name == \"ChiSquared\":\n",
    "        scores, _ = chi2(X_scaled, y)\n",
    "\n",
    "    elif method_name == \"RFE\":\n",
    "        selector.fit(X_scaled, y)\n",
    "        scores = -selector.ranking_  # lower is better, so invert for plotting\n",
    "\n",
    "    elif method_name == \"ForwardSelection\":\n",
    "        selector.fit(X_scaled, y)\n",
    "        scores = selector.get_support().astype(int)  # 1 for selected, 0 otherwise\n",
    "\n",
    "    else:\n",
    "        continue\n",
    "    # index as x axi  Plotting\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.bar(range(X.shape[1]), scores)\n",
    "    plt.xlabel(\"Feature Index\")\n",
    "    plt.ylabel(\"Score / Importance\")\n",
    "    plt.title(f\"{method_name}: Feature Ranking Scores\")\n",
    "    plt.tight_layout()\n",
    "    #plt.show()\n",
    "\n",
    "    # Save plot\n",
    "    output_folder = os.path.join(base_path4, f\"{method_name}_RESULTS\")\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    # Save the plot\n",
    "    plot_path = os.path.join(output_folder, f\"{method_name}_feature_scores.png\")\n",
    "    plt.savefig(plot_path)\n",
    "    print(f\" Plot saved to: {plot_path}\")\n",
    "    plt.close()  # Close the plot to free memory\n",
    "    # Save feature names and scores\n",
    "\n",
    "\n",
    "'''\n",
    "    # feature nmaes as x axis \n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        feature_names = np.array(X.columns)\n",
    "    else:\n",
    "        feature_names = np.array([f\"Feature {i}\" for i in range(X.shape[1])])\n",
    "\n",
    "    sorted_indices = np.argsort(scores)[::-1]\n",
    "    sorted_scores = scores[sorted_indices]\n",
    "    sorted_feature_names = feature_names[sorted_indices]\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.bar(sorted_feature_names, sorted_scores)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.xlabel(\"Feature Name\")\n",
    "    plt.ylabel(\"Score / Importance\")\n",
    "    plt.title(f\"{method_name} Feature Scores\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b738d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install kneed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf15681",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kneed import KneeLocator\n",
    "\n",
    "suggested_k = {}\n",
    "\n",
    "for method_name, selector in feature_methods.items():\n",
    "    print(f\"üìä Feature Score Analysis: {method_name}\")\n",
    "    \n",
    "    if method_name == \"ChiSquared\":\n",
    "        X_scaled = MinMaxScaler().fit_transform(X)\n",
    "    else:\n",
    "        X_scaled = X.copy()\n",
    "\n",
    "    if method_name in [\"RandomForestImportance\", \"DecisionTreeImportance\"]:\n",
    "        selector.fit(X_scaled, y)\n",
    "        scores = selector.feature_importances_\n",
    "\n",
    "    elif method_name == \"ANOVA\":\n",
    "        scores, _ = f_classif(X_scaled, y)\n",
    "\n",
    "    elif method_name == \"ChiSquared\":\n",
    "        scores, _ = chi2(X_scaled, y)\n",
    "\n",
    "    elif method_name == \"RFE\":\n",
    "        selector.fit(X_scaled, y)\n",
    "        scores = -selector.ranking_  # Invert so higher is better\n",
    "\n",
    "    elif method_name == \"ForwardSelection\":\n",
    "        selector.fit(X_scaled, y)\n",
    "        scores = selector.get_support().astype(int)  # Not useful for ranking\n",
    "        suggested_k[method_name] = np.sum(scores)\n",
    "        continue  # skip plotting for binary mask\n",
    "\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    sorted_scores = sorted(scores, reverse=True)\n",
    "    kl = KneeLocator(range(1, len(sorted_scores)+1), sorted_scores, curve=\"convex\", direction=\"decreasing\")\n",
    "    k = kl.knee if kl.knee is not None else 10  # fallback if knee not found\n",
    "    suggested_k[method_name] = k\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(range(1, len(sorted_scores)+1), sorted_scores, marker='o')\n",
    "    if kl.knee:\n",
    "        plt.axvline(k, color='red', linestyle='--', label=f'k = {k}')\n",
    "    plt.title(f\"{method_name} - Score Curve with Elbow\")\n",
    "    plt.xlabel(\"Feature Rank\")\n",
    "    plt.ylabel(\"Score / Importance\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    #plt.show()\n",
    "    # Save plot\n",
    "    output_folder = os.path.join(base_path4, f\"{method_name}_RESULTS\")\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    plot_path = os.path.join(output_folder, f\"{method_name}_elbow_plot.png\")\n",
    "    plt.savefig(plot_path)\n",
    "    print(f\" Elbow plot saved to: {plot_path}\")\n",
    "    plt.close()  # Close the plot to free memory\n",
    "print(\"\\nüìå Suggested `k` values:\")\n",
    "for method, k in suggested_k.items():\n",
    "    print(f\"  {method}: k = {k}\")\n",
    "# Save suggested k values\n",
    "suggested_k_path = os.path.join(base_path4, \"suggested_k_values.csv\")\n",
    "suggested_k_df = pd.DataFrame(list(suggested_k.items()), columns=[\"Method\", \"Suggested k\"])\n",
    "suggested_k_df.to_csv(suggested_k_path, index=False)\n",
    "print(f\"Suggested k values saved to: {suggested_k_path}\")\n",
    "# Save feature names and scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44612cd4",
   "metadata": {},
   "source": [
    "\n",
    "### üß† **What is `kneed` doing?**\n",
    "\n",
    "**`kneed`** uses the **elbow method** to find the point where a curve (like feature importance or score) **starts to flatten** ‚Äî this point is called the **\"knee\"** or **\"elbow\"**.\n",
    "\n",
    "### üîç Why?\n",
    "\n",
    "In feature selection, plotting scores sorted in descending order often shows:\n",
    "\n",
    "* Sharp drops for important features\n",
    "* A plateau for less informative features\n",
    "\n",
    "The **elbow point** is a natural choice for `k`, the number of important features to keep.\n",
    "\n",
    "---\n",
    "\n",
    "### üìâ How it works internally:\n",
    "\n",
    "* It looks at the curve formed by feature scores.\n",
    "* Fits a **convex/concave curve**.\n",
    "* Finds the point where the **slope changes sharply** ‚Äî this is the \"knee\".\n",
    "\n",
    "So `kneed` helps find this point **programmatically**, instead of visually inspecting every time.\n",
    "\n",
    "---\n",
    "\n",
    "## üìà **What is this \"score\"?** (No heading shown in your plots)\n",
    "\n",
    "It depends on the method:\n",
    "\n",
    "| Feature Method       | \"Score\" Meaning                                             |\n",
    "| -------------------- | ----------------------------------------------------------- |\n",
    "| **ANOVA**            | F-statistic (higher = feature better separates classes)     |\n",
    "| **ChiSquared**       | Chi-squared test statistic (measures dependency with label) |\n",
    "| **RandomForest/DT**  | Gini-based or entropy-based importance                      |\n",
    "| **RFE**              | Feature rank (lower = better), inverted here for plotting   |\n",
    "| **ForwardSelection** | Binary mask (1 = selected, but no ranking available)        |\n",
    "\n",
    "So this **score axis** on your plot is:\n",
    "\n",
    "> How much a feature contributes to predicting the target ‚Äî as defined by each selection method.\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ Summary:\n",
    "\n",
    "* `kneed` uses **curve shape** to find where **score importance levels off**.\n",
    "* The **\"score\"** depends on statistical strength or model-based importance.\n",
    "* This helps pick a smart `k` without arbitrary guessing.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50424d41",
   "metadata": {},
   "source": [
    "The \"score\" represents how important or useful each feature is for predicting the target variable ‚Äî but the exact meaning depends on the method used:\n",
    "\n",
    "* **In ANOVA (f\\_classif)**:\n",
    "  The score is the **F-statistic**, which compares the variance **between groups (classes)** to the variance **within groups**. A high F-value means the feature separates classes well ‚Äî it's strongly correlated with the output.\n",
    "\n",
    "* **In Chi-Squared test (chi2)**:\n",
    "  The score is the **Chi-squared statistic**, which tests **independence** between the feature and the target. A high score means the feature and the target are likely **dependent** (i.e., the feature gives useful info about the target).\n",
    "\n",
    "* **In Random Forest / Decision Tree**:\n",
    "  The score is based on **feature importance**, calculated from how much a feature **reduces impurity (like Gini or entropy)** across all trees. Features that help split the data cleanly (low impurity) get higher importance scores.\n",
    "\n",
    "* **In RFE (Recursive Feature Elimination)**:\n",
    "  This method doesn't give scores directly but ranks features by how important they are to a model (e.g., logistic regression). We convert ranks into scores by taking the **negative rank**, so better-ranked features have higher scores.\n",
    "\n",
    "* **In Forward Selection**:\n",
    "  There‚Äôs no direct score; it selects a subset of features step-by-step based on which one improves the model most at each step. The result is a binary yes/no for each feature (selected or not), not a numeric score.\n",
    "\n",
    "In all cases, higher scores mean the feature is more useful or informative for the prediction task.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a44ad4",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
